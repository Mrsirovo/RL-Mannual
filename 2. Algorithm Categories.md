# ALGORITHM CATEGORIES  

### **Model-Free vs Model-Based**  

- **Model-Free**:  
  Algorithms that **do not explicitly learn the environmentâ€™s dynamics** (transition probability $P$ and reward function $R$). Instead, they directly optimize value functions or policies based on interactions with the environment.  
  - **Examples**: Q-Learning, Policy Gradient, DQN, SAC.  

- **Model-Based**:  
  Algorithms that **learn a model of the environment** (i.e., $P(s'|s,a)$ and $R(s,a)$ ) and use it for planning or policy optimization.  
  - **Examples**: Dyna-Q, Monte Carlo Tree Search (MCTS), Model-Based PPO.  

---

### **Online vs Offline**  

- **Online Learning**:  
  Algorithms that **learn in real-time** by interacting with the environment. Data is collected **on-the-fly** and used immediately for learning.  
  - **Examples**: SARSA, Q-Learning, PPO.  

- **Offline Learning (Batch RL)**:  
  Algorithms that **learn from a fixed dataset** of experiences collected prior to training, without further interaction with the environment.  
  - **Examples**: Offline DQN, BCQ (Batch-Constrained Q-learning), CQL (Conservative Q-Learning).  

---
